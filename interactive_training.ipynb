{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPHtbJl/dd49wCaJQTeHsrU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnny24595/LearnPython/blob/main/interactive_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Interactive LLM session**"
      ],
      "metadata": {
        "id": "cceV0HmbZUdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Table of Contents</h2>\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "    <ul>\n",
        "        <li>\n",
        "            <a href=\"#Setting up the environment\">Setting up the environment</a></li>\n",
        "            <li><a href=\"#Understand basic LLM codeblocks\">Understand basic LLM codeblocks</a></li>\n",
        "            <li><a href=\"#Adjust prompt to change LLM behaviour\">Adjust prompt to change LLM behaviour</a></li>\n",
        "            <li><a href=\"#Basic use case examples\">Basic use case examples</a></li>\n",
        "            <li><a href=\"#Advanced LLM techniques\">Advanced LLM techniques</a></li>\n",
        "            <li><a href=\"#Your turn, program a basic LLM use case!\">Your turn, program a basic LLM use case!</a></li>\n",
        "\n",
        "</div>\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "SqMYBWp0YCIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setting up the environment**"
      ],
      "metadata": {
        "id": "wkolp_iRsHVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insert the received API key between the \" \": os.environ[\"OPENAI_API_KEY\"] = \"examplekey123\""
      ],
      "metadata": {
        "id": "UL_0__r1ZnXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\" # Insert OpenAI API key here"
      ],
      "metadata": {
        "id": "U4I9w4J33OPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this codeblock to install the necessary python packages in the training environment!"
      ],
      "metadata": {
        "id": "gG8isQZbZ4Tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain langchain_community openai"
      ],
      "metadata": {
        "id": "I8dutj9Lo21N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>"
      ],
      "metadata": {
        "id": "_aQX1yFAXpbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Understand basic LLM codeblocks**"
      ],
      "metadata": {
        "id": "aY_PhzLwaB6N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNwx_X80oRqE"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0.9)\n",
        "\n",
        "text = \"Suggest a personalized workout routine for someone looking to improve cardiovascular endurance and prefers outdoor activities.\"\n",
        "\n",
        "print(llm(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Challenge #1:**\n",
        "\n",
        "Let the model come up with a joke about consultants!"
      ],
      "metadata": {
        "id": "UlEf9Pe7XBx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your code here and run the cell!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wgv44cqiW1gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>"
      ],
      "metadata": {
        "id": "BxlQbhT8j7DH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Adjust prompt to change LLM behaviour**\n"
      ],
      "metadata": {
        "id": "NOLm0LyysguZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up a system prompt to change LLM behaviour!"
      ],
      "metadata": {
        "id": "d4ocNjRPcDuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0.9)\n",
        "\n",
        "Systemprompt = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=\"\"\"\n",
        "    Answer like Donald Trump to this query: {query}?\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=Systemprompt)\n",
        "\n",
        "query = \"Suggest a personalized workout routine for someone looking to improve cardiovascular endurance and prefers outdoor activities.\"\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "print(chain.run(query))"
      ],
      "metadata": {
        "id": "8tvttkyzsCCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Challenge #2:**\n",
        "Setup these rules for the model to answer the query:\n",
        "1. Always brag about yourself and how good you are in answering queries.\n",
        "2. Always end your answer with a goodbye.\n",
        "3. Always format your response so it readable.\n",
        "4. Always give yourself a name.\n",
        "5. Always use emojis."
      ],
      "metadata": {
        "id": "9aBWMHiEcaNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your code here and run the cell!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_PZClvPscTac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>"
      ],
      "metadata": {
        "id": "q_PL69Wlj8_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Basic use case examples**"
      ],
      "metadata": {
        "id": "VKfmLgIh-VFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic use cases of LLM models include:\n",
        "1. Translation\n",
        "2. Text classification\n",
        "3. Summarization\n",
        "4. Code generation"
      ],
      "metadata": {
        "id": "NdmpLWTwktCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0.9)\n",
        "\n",
        "Systemprompt = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=\"Translate this query into german: {query}?\",\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=Systemprompt)\n",
        "\n",
        "query = \"\"\"\n",
        "Suggest a personalized workout routine for someone looking to improve cardiovascular endurance and prefers outdoor activities.\n",
        "\"\"\"\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "print(chain.run(query))"
      ],
      "metadata": {
        "id": "RH6cvpV3vh6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Challenge #3:** Make the model summarize this text:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> In recent years, the global push towards renewable energy has accelerated significantly. Countries around the world are investing heavily in solar, wind, and hydroelectric power, aiming to reduce their reliance on fossil fuels and mitigate the effects of climate change. Solar power, in particular, has seen remarkable growth due to advancements in photovoltaic technology, which have made solar panels more efficient and affordable.\n",
        "The economic benefits of renewable energy are substantial. By creating jobs in the manufacturing, installation, and maintenance of renewable energy systems, countries can stimulate their economies. Additionally, renewable energy sources often provide more stable and predictable energy prices compared to fossil fuels, which are subject to volatile market fluctuations.\n",
        "Environmental impacts are also a major consideration. Unlike fossil fuels, renewable energy sources produce little to no greenhouse gas emissions during operation. This reduction in emissions is crucial for meeting international climate targets and protecting ecosystems from the adverse effects of global warming. Moreover, renewable energy projects, such as wind farms and solar parks, can be designed to minimize their impact on local wildlife and habitats.\n",
        "Despite these advantages, there are challenges to the widespread adoption of renewable energy. One significant hurdle is the intermittency of sources like solar and wind power, which do not produce energy continuously. To address this, researchers are developing better energy storage solutions, such as advanced battery systems, to store excess energy generated during peak production times for use during periods of low production.\n",
        "Furthermore, the transition to renewable energy requires substantial investment in new infrastructure, including power grids capable of integrating diverse energy sources. Policymakers must also navigate regulatory and market barriers to create an environment conducive to renewable energy development. Public support and awareness are crucial, as community buy-in can drive local renewable energy initiatives and ensure their long-term success.\n",
        "Overall, the shift towards renewable energy is not only an environmental imperative but also an economic opportunity. By overcoming the challenges and leveraging the benefits, societies can move towards a more sustainable and resilient energy future.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ycicC2p0lC7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your code here and run the cell!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QOVsiogHlBdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>"
      ],
      "metadata": {
        "id": "ARdBL1xepitP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Advanced LLM techniques**"
      ],
      "metadata": {
        "id": "sJaiHV3x-P3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to enter multiple inputs into the same template:"
      ],
      "metadata": {
        "id": "6Qd_LqeQn0f3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0.9)\n",
        "\n",
        "template = \"\"\"\n",
        "Suggest a personalized workout routine for a person that is {age} years old, looking to improve cardiovascular endurance and prefers {prefered_activities}.\n",
        "\"\"\"\n",
        "\n",
        "Systemprompt = PromptTemplate(\n",
        "    input_variables=[\"age\", \"prefered_activities\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "# Input data for the prompt\n",
        "input_data = {\"age\": \"60\", \"prefered_activities\": \"indoor_activities\"}\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=Systemprompt)\n",
        "\n",
        "# Run the chain and save response into variable\n",
        "response = chain.run(input_data)\n",
        "\n",
        "# Print response\n",
        "print(response)"
      ],
      "metadata": {
        "id": "jwC0w2r0mNGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Challenge #4:** Change the template, so that the input variables are now the **gender** of the person that the routine is suggested for and the **area where the person wants to improve** (e.g. cardiovascular endurance)\n"
      ],
      "metadata": {
        "id": "5hqxpkGjn9qN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your code here and run the cell!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0DRYn43Un8hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>"
      ],
      "metadata": {
        "id": "x0JobybiplAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the answer of an LLM into a variable and use it as input for a second chain."
      ],
      "metadata": {
        "id": "ZmtPDkAGpsW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0.9)\n",
        "\n",
        "query = \"\"\"\n",
        "Come up with a short newspaper article with maximum 200 words.\n",
        "The article will be classified with another LLM as either good news or bad news so dont include the classification in your answer.\n",
        "\"\"\"\n",
        "\n",
        "Systemprompt_1 = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=\"Answer this query {query}\",\n",
        ")\n",
        "\n",
        "chain_1 = LLMChain(llm=llm, prompt=Systemprompt_1)\n",
        "\n",
        "# Run the chain and save response into variable\n",
        "response_1 = chain_1.run(query)\n",
        "\n",
        "# Print response\n",
        "print(\"Reponse 1:\")\n",
        "print(response_1)\n",
        "\n",
        "\n",
        "\n",
        "# Second chain starts here\n",
        "\n",
        "template = \"\"\"\n",
        "Classify this newspaper article either as good or bad news {article}.\n",
        "Also give a quick reasoning how you came to this conclusion.\n",
        "\"\"\"\n",
        "\n",
        "Systemprompt_2 = PromptTemplate(\n",
        "    input_variables=[\"article\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "# Input data for the prompt\n",
        "input_data = {\"article\": response_1}\n",
        "\n",
        "chain_2 = LLMChain(llm=llm, prompt=Systemprompt_2)\n",
        "\n",
        "response_2 = chain_2.run(input_data)\n",
        "\n",
        "print(\"Reponse 2:\")\n",
        "print(response_2)\n",
        "\n"
      ],
      "metadata": {
        "id": "vFC9t9RwAx9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>"
      ],
      "metadata": {
        "id": "6i1i-1rK4zDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Your turn, program a basic LLM use case!**"
      ],
      "metadata": {
        "id": "oJQgrHra4-CT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Challenge:** Now its your turn - implement your first own LLM use case!\n",
        "You have learned all necessary tools to implement the use case in this interactive tutorial.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "`COPY - PASTE -ADAPT`\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Implement a 2 step use case:\n",
        "*Scenario: Quality incident classification*\n",
        "---\n",
        "\n",
        "\n",
        "1. Step: Let the LLM generate a realistic quality incident in the production of a drone. The incident should be given in an unstructured form.\n",
        "2. Step: Let the LLM classify the quality incident from Step 1 to read out only the necessary details e.g., quality incident labels, root cause, short-term actions, long-term actions. Make sure the output is structured.\n",
        "\n",
        "*Tip: You can specify which information the quality incident should contain in Step 1.*\n",
        "\n"
      ],
      "metadata": {
        "id": "QCQm0kee5BYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your code here and run the cell!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ebzq1GQOtxPw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}